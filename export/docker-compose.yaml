version: '3'

services:
  tf-serving-server:
    container_name: tf-serving-server
    image: $USER/tensorflow-serving-devel-cpu
    networks:
      - tf_serving
    ports:
      - "9000:9000"
    links:
      - client
    expose:
      - "9000"
    volumes:
      - ~/:/host
    command: bazel-bin/tensorflow_serving/model_servers/tensorflow_model_server --port=9000 --model_name=keras_model --model_base_path=/host/data_hdd/ctc/ss/example/deploy_estimator
  tf-serving-client:
    image: "tensorflow/tensorflow:1.9.0-rc1-devel-py3"
    networks:
      - tf_serving
    ports:
      - "5000:5000"
    environment:
      - TF_SERVER_NAME=tf-serving-server
      - TF_SERVER_PORT=9000
      - FLASK_SERVER_NAME=0.0.0.0
      - FLASK_SERVER_PORT=5000
      - FLASK_DEBUG=1
    depends_on:
      - tf-serving-server

networks:
  tf_serving:
    driver: bridge
